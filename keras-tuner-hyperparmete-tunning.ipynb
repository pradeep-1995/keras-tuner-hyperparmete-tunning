{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-03T08:11:10.526870Z","iopub.execute_input":"2023-07-03T08:11:10.527425Z","iopub.status.idle":"2023-07-03T08:11:10.569451Z","shell.execute_reply.started":"2023-07-03T08:11:10.527368Z","shell.execute_reply":"2023-07-03T08:11:10.568483Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:10.571038Z","iopub.execute_input":"2023-07-03T08:11:10.572303Z","iopub.status.idle":"2023-07-03T08:11:10.630484Z","shell.execute_reply.started":"2023-07-03T08:11:10.572267Z","shell.execute_reply":"2023-07-03T08:11:10.628605Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.corr()['Outcome']","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:10.633444Z","iopub.execute_input":"2023-07-03T08:11:10.633893Z","iopub.status.idle":"2023-07-03T08:11:10.650451Z","shell.execute_reply.started":"2023-07-03T08:11:10.633855Z","shell.execute_reply":"2023-07-03T08:11:10.648970Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Pregnancies                 0.221898\nGlucose                     0.466581\nBloodPressure               0.065068\nSkinThickness               0.074752\nInsulin                     0.130548\nBMI                         0.292695\nDiabetesPedigreeFunction    0.173844\nAge                         0.238356\nOutcome                     1.000000\nName: Outcome, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"X = df.iloc[:,0:8].values\nY = df.iloc[:,-1].values\n\nX.shape , Y.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:10.652830Z","iopub.execute_input":"2023-07-03T08:11:10.653533Z","iopub.status.idle":"2023-07-03T08:11:10.666010Z","shell.execute_reply.started":"2023-07-03T08:11:10.653496Z","shell.execute_reply":"2023-07-03T08:11:10.664479Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"((768, 8), (768,))"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX = scaler.fit_transform(X)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:10.669002Z","iopub.execute_input":"2023-07-03T08:11:10.669346Z","iopub.status.idle":"2023-07-03T08:11:12.170991Z","shell.execute_reply.started":"2023-07-03T08:11:10.669318Z","shell.execute_reply":"2023-07-03T08:11:12.169632Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(768, 8)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=2)\nX_train.shape , Y_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:12.172628Z","iopub.execute_input":"2023-07-03T08:11:12.172958Z","iopub.status.idle":"2023-07-03T08:11:12.312569Z","shell.execute_reply.started":"2023-07-03T08:11:12.172930Z","shell.execute_reply":"2023-07-03T08:11:12.311451Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"((614, 8), (614,))"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Dense,Dropout","metadata":{"execution":{"iopub.status.busy":"2023-07-03T09:17:45.596695Z","iopub.execute_input":"2023-07-03T09:17:45.597113Z","iopub.status.idle":"2023-07-03T09:17:45.603305Z","shell.execute_reply.started":"2023-07-03T09:17:45.597080Z","shell.execute_reply":"2023-07-03T09:17:45.602419Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(32,activation='relu',input_dim=8))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\nmodel.fit(X_train,Y_train,batch_size=32,epochs=100,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:22.836705Z","iopub.execute_input":"2023-07-03T08:11:22.838675Z","iopub.status.idle":"2023-07-03T08:11:32.802358Z","shell.execute_reply.started":"2023-07-03T08:11:22.838596Z","shell.execute_reply":"2023-07-03T08:11:32.801111Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/100\n20/20 [==============================] - 1s 16ms/step - loss: 0.6920 - accuracy: 0.5977 - val_loss: 0.6392 - val_accuracy: 0.6688\nEpoch 2/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.6694 - val_loss: 0.5977 - val_accuracy: 0.7208\nEpoch 3/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.7117 - val_loss: 0.5630 - val_accuracy: 0.7338\nEpoch 4/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7378 - val_loss: 0.5375 - val_accuracy: 0.7273\nEpoch 5/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7345 - val_loss: 0.5180 - val_accuracy: 0.7468\nEpoch 6/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7508 - val_loss: 0.5039 - val_accuracy: 0.7727\nEpoch 7/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7508 - val_loss: 0.4941 - val_accuracy: 0.7727\nEpoch 8/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7622 - val_loss: 0.4829 - val_accuracy: 0.7857\nEpoch 9/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7736 - val_loss: 0.4765 - val_accuracy: 0.7792\nEpoch 10/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7785 - val_loss: 0.4711 - val_accuracy: 0.7792\nEpoch 11/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7785 - val_loss: 0.4659 - val_accuracy: 0.7857\nEpoch 12/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7769 - val_loss: 0.4642 - val_accuracy: 0.7727\nEpoch 13/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7834 - val_loss: 0.4621 - val_accuracy: 0.7727\nEpoch 14/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7850 - val_loss: 0.4617 - val_accuracy: 0.7662\nEpoch 15/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7818 - val_loss: 0.4583 - val_accuracy: 0.7597\nEpoch 16/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7834 - val_loss: 0.4562 - val_accuracy: 0.7597\nEpoch 17/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7899 - val_loss: 0.4577 - val_accuracy: 0.7597\nEpoch 18/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7866 - val_loss: 0.4587 - val_accuracy: 0.7532\nEpoch 19/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7932 - val_loss: 0.4579 - val_accuracy: 0.7532\nEpoch 20/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7915 - val_loss: 0.4575 - val_accuracy: 0.7532\nEpoch 21/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.7915 - val_loss: 0.4584 - val_accuracy: 0.7532\nEpoch 22/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7915 - val_loss: 0.4575 - val_accuracy: 0.7597\nEpoch 23/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7948 - val_loss: 0.4580 - val_accuracy: 0.7597\nEpoch 24/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7932 - val_loss: 0.4571 - val_accuracy: 0.7662\nEpoch 25/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7932 - val_loss: 0.4574 - val_accuracy: 0.7662\nEpoch 26/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7932 - val_loss: 0.4599 - val_accuracy: 0.7727\nEpoch 27/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7948 - val_loss: 0.4562 - val_accuracy: 0.7662\nEpoch 28/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7932 - val_loss: 0.4590 - val_accuracy: 0.7662\nEpoch 29/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7997 - val_loss: 0.4589 - val_accuracy: 0.7727\nEpoch 30/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7964 - val_loss: 0.4576 - val_accuracy: 0.7727\nEpoch 31/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7997 - val_loss: 0.4587 - val_accuracy: 0.7792\nEpoch 32/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7997 - val_loss: 0.4589 - val_accuracy: 0.7662\nEpoch 33/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7997 - val_loss: 0.4588 - val_accuracy: 0.7662\nEpoch 34/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7980 - val_loss: 0.4605 - val_accuracy: 0.7662\nEpoch 35/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7980 - val_loss: 0.4586 - val_accuracy: 0.7662\nEpoch 36/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7997 - val_loss: 0.4582 - val_accuracy: 0.7662\nEpoch 37/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7997 - val_loss: 0.4593 - val_accuracy: 0.7597\nEpoch 38/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7997 - val_loss: 0.4584 - val_accuracy: 0.7727\nEpoch 39/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8029 - val_loss: 0.4598 - val_accuracy: 0.7597\nEpoch 40/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8062 - val_loss: 0.4598 - val_accuracy: 0.7597\nEpoch 41/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8029 - val_loss: 0.4593 - val_accuracy: 0.7597\nEpoch 42/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8046 - val_loss: 0.4594 - val_accuracy: 0.7597\nEpoch 43/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7964 - val_loss: 0.4574 - val_accuracy: 0.7727\nEpoch 44/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.7997 - val_loss: 0.4574 - val_accuracy: 0.7662\nEpoch 45/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.8046 - val_loss: 0.4593 - val_accuracy: 0.7597\nEpoch 46/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8029 - val_loss: 0.4593 - val_accuracy: 0.7597\nEpoch 47/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8013 - val_loss: 0.4595 - val_accuracy: 0.7597\nEpoch 48/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7997 - val_loss: 0.4605 - val_accuracy: 0.7597\nEpoch 49/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7980 - val_loss: 0.4602 - val_accuracy: 0.7597\nEpoch 50/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7980 - val_loss: 0.4615 - val_accuracy: 0.7727\nEpoch 51/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.8013 - val_loss: 0.4598 - val_accuracy: 0.7727\nEpoch 52/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7964 - val_loss: 0.4617 - val_accuracy: 0.7727\nEpoch 53/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7997 - val_loss: 0.4619 - val_accuracy: 0.7597\nEpoch 54/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7980 - val_loss: 0.4610 - val_accuracy: 0.7792\nEpoch 55/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8013 - val_loss: 0.4594 - val_accuracy: 0.7857\nEpoch 56/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7997 - val_loss: 0.4586 - val_accuracy: 0.7857\nEpoch 57/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7980 - val_loss: 0.4605 - val_accuracy: 0.7792\nEpoch 58/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.7997 - val_loss: 0.4618 - val_accuracy: 0.7727\nEpoch 59/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7948 - val_loss: 0.4622 - val_accuracy: 0.7922\nEpoch 60/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.7997 - val_loss: 0.4611 - val_accuracy: 0.7922\nEpoch 61/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8013 - val_loss: 0.4601 - val_accuracy: 0.7857\nEpoch 62/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8029 - val_loss: 0.4609 - val_accuracy: 0.7792\nEpoch 63/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.7997 - val_loss: 0.4613 - val_accuracy: 0.7727\nEpoch 64/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7997 - val_loss: 0.4601 - val_accuracy: 0.7792\nEpoch 65/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8046 - val_loss: 0.4603 - val_accuracy: 0.7857\nEpoch 66/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8078 - val_loss: 0.4618 - val_accuracy: 0.7662\nEpoch 67/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8062 - val_loss: 0.4612 - val_accuracy: 0.7792\nEpoch 68/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8078 - val_loss: 0.4612 - val_accuracy: 0.7727\nEpoch 69/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8111 - val_loss: 0.4607 - val_accuracy: 0.7727\nEpoch 70/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8094 - val_loss: 0.4611 - val_accuracy: 0.7727\nEpoch 71/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8078 - val_loss: 0.4623 - val_accuracy: 0.7727\nEpoch 72/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8013 - val_loss: 0.4611 - val_accuracy: 0.7792\nEpoch 73/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8111 - val_loss: 0.4608 - val_accuracy: 0.7727\nEpoch 74/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8078 - val_loss: 0.4596 - val_accuracy: 0.7857\nEpoch 75/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8046 - val_loss: 0.4615 - val_accuracy: 0.7727\nEpoch 76/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.8094 - val_loss: 0.4627 - val_accuracy: 0.7727\nEpoch 77/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.8062 - val_loss: 0.4618 - val_accuracy: 0.7727\nEpoch 78/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.8029 - val_loss: 0.4628 - val_accuracy: 0.7727\nEpoch 79/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8094 - val_loss: 0.4602 - val_accuracy: 0.7727\nEpoch 80/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8094 - val_loss: 0.4605 - val_accuracy: 0.7727\nEpoch 81/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8062 - val_loss: 0.4627 - val_accuracy: 0.7792\nEpoch 82/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8046 - val_loss: 0.4599 - val_accuracy: 0.7727\nEpoch 83/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.8078 - val_loss: 0.4579 - val_accuracy: 0.7857\nEpoch 84/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8062 - val_loss: 0.4586 - val_accuracy: 0.7857\nEpoch 85/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8094 - val_loss: 0.4595 - val_accuracy: 0.7857\nEpoch 86/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8078 - val_loss: 0.4584 - val_accuracy: 0.7857\nEpoch 87/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8127 - val_loss: 0.4597 - val_accuracy: 0.7727\nEpoch 88/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8111 - val_loss: 0.4590 - val_accuracy: 0.7792\nEpoch 89/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8143 - val_loss: 0.4606 - val_accuracy: 0.7727\nEpoch 90/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8111 - val_loss: 0.4597 - val_accuracy: 0.7727\nEpoch 91/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8111 - val_loss: 0.4609 - val_accuracy: 0.7792\nEpoch 92/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8062 - val_loss: 0.4605 - val_accuracy: 0.7727\nEpoch 93/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4098 - accuracy: 0.8062 - val_loss: 0.4614 - val_accuracy: 0.7792\nEpoch 94/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8094 - val_loss: 0.4615 - val_accuracy: 0.7792\nEpoch 95/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8094 - val_loss: 0.4619 - val_accuracy: 0.7792\nEpoch 96/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8094 - val_loss: 0.4620 - val_accuracy: 0.7727\nEpoch 97/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8029 - val_loss: 0.4611 - val_accuracy: 0.7727\nEpoch 98/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8046 - val_loss: 0.4624 - val_accuracy: 0.7727\nEpoch 99/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8062 - val_loss: 0.4609 - val_accuracy: 0.7727\nEpoch 100/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8078 - val_loss: 0.4599 - val_accuracy: 0.7662\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fec347512a0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### **KerasTuner Hyperparameter:**\n#### **1. To Select Appropriate Optimizer**","metadata":{}},{"cell_type":"code","source":"!pip install -U keras-tuner","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:32.806081Z","iopub.execute_input":"2023-07-03T08:11:32.806474Z","iopub.status.idle":"2023-07-03T08:11:47.919438Z","shell.execute_reply.started":"2023-07-03T08:11:32.806443Z","shell.execute_reply":"2023-07-03T08:11:47.917925Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-tuner in /opt/conda/lib/python3.10/site-packages (1.3.5)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (2.28.2)\nRequirement already satisfied: kt-legacy in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-tuner) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import keras_tuner as kt","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:47.926603Z","iopub.execute_input":"2023-07-03T08:11:47.927054Z","iopub.status.idle":"2023-07-03T08:11:48.132828Z","shell.execute_reply.started":"2023-07-03T08:11:47.927002Z","shell.execute_reply":"2023-07-03T08:11:48.131875Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def build_model(hp):\n    \n    model = Sequential()\n    \n    model.add(Dense(32,activation='relu',input_dim=8))\n    model.add(Dense(1,activation='sigmoid'))\n    \n    optimizer = hp.Choice('optimizer',values=['adam','sgd','rmsprop','adadelta'])\n    # hp.choice contain a string and list of value ,string contain any name but it nessary to assigne\n    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:48.134518Z","iopub.execute_input":"2023-07-03T08:11:48.135276Z","iopub.status.idle":"2023-07-03T08:11:48.144695Z","shell.execute_reply.started":"2023-07-03T08:11:48.135226Z","shell.execute_reply":"2023-07-03T08:11:48.143603Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"tuner = kt.RandomSearch(build_model,objective='val_accuracy',max_trials=5)","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:48.146516Z","iopub.execute_input":"2023-07-03T08:11:48.147398Z","iopub.status.idle":"2023-07-03T08:11:48.218685Z","shell.execute_reply.started":"2023-07-03T08:11:48.147335Z","shell.execute_reply":"2023-07-03T08:11:48.217286Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tuner.search(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:48.220179Z","iopub.execute_input":"2023-07-03T08:11:48.220551Z","iopub.status.idle":"2023-07-03T08:11:56.836227Z","shell.execute_reply.started":"2023-07-03T08:11:48.220520Z","shell.execute_reply":"2023-07-03T08:11:56.835024Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Trial 4 Complete [00h 00m 02s]\nval_accuracy: 0.26623377203941345\n\nBest val_accuracy So Far: 0.7727272510528564\nTotal elapsed time: 00h 00m 09s\n","output_type":"stream"}]},{"cell_type":"code","source":"# Best perform model\ntuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:56.837633Z","iopub.execute_input":"2023-07-03T08:11:56.838288Z","iopub.status.idle":"2023-07-03T08:11:56.846092Z","shell.execute_reply.started":"2023-07-03T08:11:56.838252Z","shell.execute_reply":"2023-07-03T08:11:56.844989Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'optimizer': 'rmsprop'}"},"metadata":{}}]},{"cell_type":"code","source":"# Use the Best model\nmodel = tuner.get_best_models(num_models=1)[0]\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:56.847941Z","iopub.execute_input":"2023-07-03T08:11:56.848294Z","iopub.status.idle":"2023-07-03T08:11:57.291632Z","shell.execute_reply.started":"2023-07-03T08:11:56.848267Z","shell.execute_reply":"2023-07-03T08:11:57.290245Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 32)                288       \n                                                                 \n dense_1 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 321\nTrainable params: 321\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(X_train,Y_train,batch_size=32,epochs=100,initial_epoch=4,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:11:57.293105Z","iopub.execute_input":"2023-07-03T08:11:57.294473Z","iopub.status.idle":"2023-07-03T08:12:05.395411Z","shell.execute_reply.started":"2023-07-03T08:11:57.294438Z","shell.execute_reply":"2023-07-03T08:12:05.394246Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 5/100\n20/20 [==============================] - 1s 16ms/step - loss: 0.5212 - accuracy: 0.7720 - val_loss: 0.5106 - val_accuracy: 0.7727\nEpoch 6/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7785 - val_loss: 0.4993 - val_accuracy: 0.7792\nEpoch 7/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.7769 - val_loss: 0.4904 - val_accuracy: 0.7792\nEpoch 8/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7752 - val_loss: 0.4829 - val_accuracy: 0.7727\nEpoch 9/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7769 - val_loss: 0.4789 - val_accuracy: 0.7727\nEpoch 10/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7752 - val_loss: 0.4761 - val_accuracy: 0.7922\nEpoch 11/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7785 - val_loss: 0.4720 - val_accuracy: 0.7922\nEpoch 12/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7769 - val_loss: 0.4722 - val_accuracy: 0.7922\nEpoch 13/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7769 - val_loss: 0.4715 - val_accuracy: 0.7922\nEpoch 14/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7736 - val_loss: 0.4687 - val_accuracy: 0.7922\nEpoch 15/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7801 - val_loss: 0.4699 - val_accuracy: 0.7857\nEpoch 16/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7818 - val_loss: 0.4709 - val_accuracy: 0.7857\nEpoch 17/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7785 - val_loss: 0.4704 - val_accuracy: 0.7792\nEpoch 18/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7801 - val_loss: 0.4689 - val_accuracy: 0.7792\nEpoch 19/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7801 - val_loss: 0.4688 - val_accuracy: 0.7727\nEpoch 20/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7785 - val_loss: 0.4683 - val_accuracy: 0.7727\nEpoch 21/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7818 - val_loss: 0.4677 - val_accuracy: 0.7727\nEpoch 22/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7850 - val_loss: 0.4672 - val_accuracy: 0.7727\nEpoch 23/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7801 - val_loss: 0.4672 - val_accuracy: 0.7727\nEpoch 24/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7818 - val_loss: 0.4669 - val_accuracy: 0.7792\nEpoch 25/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7818 - val_loss: 0.4667 - val_accuracy: 0.7792\nEpoch 26/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7818 - val_loss: 0.4656 - val_accuracy: 0.7792\nEpoch 27/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7818 - val_loss: 0.4654 - val_accuracy: 0.7792\nEpoch 28/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7866 - val_loss: 0.4656 - val_accuracy: 0.7727\nEpoch 29/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7850 - val_loss: 0.4662 - val_accuracy: 0.7727\nEpoch 30/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7850 - val_loss: 0.4661 - val_accuracy: 0.7727\nEpoch 31/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7883 - val_loss: 0.4676 - val_accuracy: 0.7727\nEpoch 32/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7850 - val_loss: 0.4679 - val_accuracy: 0.7727\nEpoch 33/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7883 - val_loss: 0.4670 - val_accuracy: 0.7727\nEpoch 34/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7850 - val_loss: 0.4661 - val_accuracy: 0.7727\nEpoch 35/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7818 - val_loss: 0.4662 - val_accuracy: 0.7727\nEpoch 36/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7866 - val_loss: 0.4675 - val_accuracy: 0.7727\nEpoch 37/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7866 - val_loss: 0.4663 - val_accuracy: 0.7792\nEpoch 38/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7850 - val_loss: 0.4659 - val_accuracy: 0.7792\nEpoch 39/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7899 - val_loss: 0.4672 - val_accuracy: 0.7727\nEpoch 40/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7850 - val_loss: 0.4683 - val_accuracy: 0.7727\nEpoch 41/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7883 - val_loss: 0.4690 - val_accuracy: 0.7727\nEpoch 42/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7932 - val_loss: 0.4689 - val_accuracy: 0.7727\nEpoch 43/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7850 - val_loss: 0.4670 - val_accuracy: 0.7727\nEpoch 44/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7866 - val_loss: 0.4654 - val_accuracy: 0.7792\nEpoch 45/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7850 - val_loss: 0.4670 - val_accuracy: 0.7857\nEpoch 46/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7883 - val_loss: 0.4668 - val_accuracy: 0.7792\nEpoch 47/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7932 - val_loss: 0.4670 - val_accuracy: 0.7857\nEpoch 48/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7948 - val_loss: 0.4672 - val_accuracy: 0.7792\nEpoch 49/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7866 - val_loss: 0.4664 - val_accuracy: 0.7857\nEpoch 50/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.4669 - val_accuracy: 0.7857\nEpoch 51/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7948 - val_loss: 0.4665 - val_accuracy: 0.7857\nEpoch 52/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.4671 - val_accuracy: 0.7857\nEpoch 53/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7915 - val_loss: 0.4666 - val_accuracy: 0.7857\nEpoch 54/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7915 - val_loss: 0.4675 - val_accuracy: 0.7792\nEpoch 55/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7915 - val_loss: 0.4689 - val_accuracy: 0.7727\nEpoch 56/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7883 - val_loss: 0.4677 - val_accuracy: 0.7792\nEpoch 57/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7932 - val_loss: 0.4675 - val_accuracy: 0.7857\nEpoch 58/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7915 - val_loss: 0.4675 - val_accuracy: 0.7857\nEpoch 59/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7948 - val_loss: 0.4685 - val_accuracy: 0.7857\nEpoch 60/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7932 - val_loss: 0.4686 - val_accuracy: 0.7857\nEpoch 61/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7948 - val_loss: 0.4688 - val_accuracy: 0.7857\nEpoch 62/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7948 - val_loss: 0.4680 - val_accuracy: 0.7922\nEpoch 63/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7964 - val_loss: 0.4696 - val_accuracy: 0.7857\nEpoch 64/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7948 - val_loss: 0.4699 - val_accuracy: 0.7857\nEpoch 65/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4248 - accuracy: 0.7899 - val_loss: 0.4679 - val_accuracy: 0.7857\nEpoch 66/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7948 - val_loss: 0.4681 - val_accuracy: 0.7922\nEpoch 67/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7948 - val_loss: 0.4671 - val_accuracy: 0.7922\nEpoch 68/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.7948 - val_loss: 0.4672 - val_accuracy: 0.7922\nEpoch 69/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7980 - val_loss: 0.4673 - val_accuracy: 0.7922\nEpoch 70/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8013 - val_loss: 0.4680 - val_accuracy: 0.7857\nEpoch 71/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7997 - val_loss: 0.4690 - val_accuracy: 0.7857\nEpoch 72/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.7997 - val_loss: 0.4674 - val_accuracy: 0.7922\nEpoch 73/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7964 - val_loss: 0.4676 - val_accuracy: 0.7922\nEpoch 74/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7997 - val_loss: 0.4690 - val_accuracy: 0.7922\nEpoch 75/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7997 - val_loss: 0.4684 - val_accuracy: 0.7922\nEpoch 76/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.7980 - val_loss: 0.4677 - val_accuracy: 0.7987\nEpoch 77/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.7997 - val_loss: 0.4690 - val_accuracy: 0.7922\nEpoch 78/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8029 - val_loss: 0.4691 - val_accuracy: 0.7922\nEpoch 79/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8029 - val_loss: 0.4692 - val_accuracy: 0.7922\nEpoch 80/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8013 - val_loss: 0.4691 - val_accuracy: 0.7922\nEpoch 81/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7980 - val_loss: 0.4709 - val_accuracy: 0.7857\nEpoch 82/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7980 - val_loss: 0.4697 - val_accuracy: 0.7922\nEpoch 83/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.7997 - val_loss: 0.4697 - val_accuracy: 0.7922\nEpoch 84/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7980 - val_loss: 0.4695 - val_accuracy: 0.7922\nEpoch 85/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.7997 - val_loss: 0.4697 - val_accuracy: 0.7922\nEpoch 86/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7997 - val_loss: 0.4697 - val_accuracy: 0.7857\nEpoch 87/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8013 - val_loss: 0.4705 - val_accuracy: 0.7792\nEpoch 88/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7980 - val_loss: 0.4708 - val_accuracy: 0.7857\nEpoch 89/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.7997 - val_loss: 0.4709 - val_accuracy: 0.7857\nEpoch 90/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7980 - val_loss: 0.4708 - val_accuracy: 0.7922\nEpoch 91/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4168 - accuracy: 0.7964 - val_loss: 0.4712 - val_accuracy: 0.7922\nEpoch 92/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7997 - val_loss: 0.4709 - val_accuracy: 0.7922\nEpoch 93/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.7932 - val_loss: 0.4684 - val_accuracy: 0.8052\nEpoch 94/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7980 - val_loss: 0.4674 - val_accuracy: 0.7987\nEpoch 95/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8062 - val_loss: 0.4683 - val_accuracy: 0.7987\nEpoch 96/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8046 - val_loss: 0.4700 - val_accuracy: 0.7922\nEpoch 97/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.7980 - val_loss: 0.4698 - val_accuracy: 0.7987\nEpoch 98/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8029 - val_loss: 0.4693 - val_accuracy: 0.7987\nEpoch 99/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8078 - val_loss: 0.4691 - val_accuracy: 0.8052\nEpoch 100/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8046 - val_loss: 0.4705 - val_accuracy: 0.7922\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fec345a2470>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### **2. Number of nodes in Layers**","metadata":{}},{"cell_type":"code","source":"def build_model1(hp):\n    \n    model = Sequential()\n    \n    units = hp.Int('units',min_value=8,max_value=128)\n    \n    model.add(Dense(units=units ,activation='relu',input_dim=8))\n    model.add(Dense(1,activation='sigmoid'))\n    \n    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:12:05.399581Z","iopub.execute_input":"2023-07-03T08:12:05.399934Z","iopub.status.idle":"2023-07-03T08:12:05.407657Z","shell.execute_reply.started":"2023-07-03T08:12:05.399905Z","shell.execute_reply":"2023-07-03T08:12:05.406280Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tuner = kt.RandomSearch(build_model1,\n                       objective='val_accuracy',\n                       max_trials=5,\n                       directory='mydir',\n                       project_name='num_nodes')","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:12:05.409022Z","iopub.execute_input":"2023-07-03T08:12:05.409334Z","iopub.status.idle":"2023-07-03T08:12:05.465062Z","shell.execute_reply.started":"2023-07-03T08:12:05.409308Z","shell.execute_reply":"2023-07-03T08:12:05.463919Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tuner.search(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:12:05.469310Z","iopub.execute_input":"2023-07-03T08:12:05.469700Z","iopub.status.idle":"2023-07-03T08:12:13.451248Z","shell.execute_reply.started":"2023-07-03T08:12:05.469669Z","shell.execute_reply":"2023-07-03T08:12:13.450003Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Trial 5 Complete [00h 00m 02s]\nval_accuracy: 0.7727272510528564\n\nBest val_accuracy So Far: 0.7727272510528564\nTotal elapsed time: 00h 00m 08s\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:12:13.452575Z","iopub.execute_input":"2023-07-03T08:12:13.452887Z","iopub.status.idle":"2023-07-03T08:12:13.459954Z","shell.execute_reply.started":"2023-07-03T08:12:13.452859Z","shell.execute_reply":"2023-07-03T08:12:13.458890Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'units': 85}"},"metadata":{}}]},{"cell_type":"code","source":"# Used best parameter\nmodel = tuner.get_best_models(num_models=1)[0]\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:12:13.461710Z","iopub.execute_input":"2023-07-03T08:12:13.462038Z","iopub.status.idle":"2023-07-03T08:12:13.834802Z","shell.execute_reply.started":"2023-07-03T08:12:13.462010Z","shell.execute_reply":"2023-07-03T08:12:13.833473Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 85)                765       \n                                                                 \n dense_1 (Dense)             (None, 1)                 86        \n                                                                 \n=================================================================\nTotal params: 851\nTrainable params: 851\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(X_train,Y_train,batch_size=32,epochs=100,initial_epoch=4,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:12:13.836105Z","iopub.execute_input":"2023-07-03T08:12:13.836465Z","iopub.status.idle":"2023-07-03T08:12:21.696476Z","shell.execute_reply.started":"2023-07-03T08:12:13.836436Z","shell.execute_reply":"2023-07-03T08:12:21.695352Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch 5/100\n20/20 [==============================] - 1s 13ms/step - loss: 0.5070 - accuracy: 0.7590 - val_loss: 0.5022 - val_accuracy: 0.7727\nEpoch 6/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7638 - val_loss: 0.4911 - val_accuracy: 0.7662\nEpoch 7/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7704 - val_loss: 0.4813 - val_accuracy: 0.7662\nEpoch 8/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7720 - val_loss: 0.4766 - val_accuracy: 0.7792\nEpoch 9/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7752 - val_loss: 0.4767 - val_accuracy: 0.7727\nEpoch 10/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7720 - val_loss: 0.4737 - val_accuracy: 0.7792\nEpoch 11/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7801 - val_loss: 0.4718 - val_accuracy: 0.7727\nEpoch 12/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7915 - val_loss: 0.4704 - val_accuracy: 0.7662\nEpoch 13/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7785 - val_loss: 0.4691 - val_accuracy: 0.7662\nEpoch 14/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7866 - val_loss: 0.4679 - val_accuracy: 0.7727\nEpoch 15/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.4697 - val_accuracy: 0.7597\nEpoch 16/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7866 - val_loss: 0.4691 - val_accuracy: 0.7662\nEpoch 17/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7850 - val_loss: 0.4707 - val_accuracy: 0.7597\nEpoch 18/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7866 - val_loss: 0.4703 - val_accuracy: 0.7597\nEpoch 19/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7948 - val_loss: 0.4673 - val_accuracy: 0.7662\nEpoch 20/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7883 - val_loss: 0.4698 - val_accuracy: 0.7597\nEpoch 21/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7866 - val_loss: 0.4684 - val_accuracy: 0.7597\nEpoch 22/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7883 - val_loss: 0.4703 - val_accuracy: 0.7597\nEpoch 23/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7866 - val_loss: 0.4670 - val_accuracy: 0.7662\nEpoch 24/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7915 - val_loss: 0.4670 - val_accuracy: 0.7662\nEpoch 25/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7866 - val_loss: 0.4681 - val_accuracy: 0.7727\nEpoch 26/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7915 - val_loss: 0.4681 - val_accuracy: 0.7597\nEpoch 27/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7899 - val_loss: 0.4682 - val_accuracy: 0.7662\nEpoch 28/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7866 - val_loss: 0.4662 - val_accuracy: 0.7727\nEpoch 29/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7883 - val_loss: 0.4656 - val_accuracy: 0.7792\nEpoch 30/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7932 - val_loss: 0.4672 - val_accuracy: 0.7727\nEpoch 31/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.4696 - val_accuracy: 0.7792\nEpoch 32/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7915 - val_loss: 0.4660 - val_accuracy: 0.7792\nEpoch 33/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7997 - val_loss: 0.4647 - val_accuracy: 0.7727\nEpoch 34/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7997 - val_loss: 0.4648 - val_accuracy: 0.7857\nEpoch 35/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7915 - val_loss: 0.4659 - val_accuracy: 0.7857\nEpoch 36/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7964 - val_loss: 0.4691 - val_accuracy: 0.7792\nEpoch 37/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7980 - val_loss: 0.4695 - val_accuracy: 0.7792\nEpoch 38/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7948 - val_loss: 0.4693 - val_accuracy: 0.7857\nEpoch 39/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7980 - val_loss: 0.4687 - val_accuracy: 0.7792\nEpoch 40/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7915 - val_loss: 0.4684 - val_accuracy: 0.7792\nEpoch 41/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.7997 - val_loss: 0.4662 - val_accuracy: 0.7857\nEpoch 42/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.7915 - val_loss: 0.4676 - val_accuracy: 0.7792\nEpoch 43/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7997 - val_loss: 0.4667 - val_accuracy: 0.7857\nEpoch 44/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.4692 - val_accuracy: 0.7727\nEpoch 45/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.7948 - val_loss: 0.4662 - val_accuracy: 0.7857\nEpoch 46/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8029 - val_loss: 0.4637 - val_accuracy: 0.7792\nEpoch 47/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7932 - val_loss: 0.4672 - val_accuracy: 0.7857\nEpoch 48/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7997 - val_loss: 0.4675 - val_accuracy: 0.7857\nEpoch 49/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.7980 - val_loss: 0.4664 - val_accuracy: 0.7792\nEpoch 50/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.7997 - val_loss: 0.4676 - val_accuracy: 0.7792\nEpoch 51/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8062 - val_loss: 0.4688 - val_accuracy: 0.7792\nEpoch 52/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.8013 - val_loss: 0.4660 - val_accuracy: 0.7792\nEpoch 53/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.4123 - accuracy: 0.8029 - val_loss: 0.4690 - val_accuracy: 0.7792\nEpoch 54/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7997 - val_loss: 0.4658 - val_accuracy: 0.7727\nEpoch 55/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8062 - val_loss: 0.4648 - val_accuracy: 0.7857\nEpoch 56/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.7997 - val_loss: 0.4668 - val_accuracy: 0.7727\nEpoch 57/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8046 - val_loss: 0.4681 - val_accuracy: 0.7857\nEpoch 58/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.7948 - val_loss: 0.4687 - val_accuracy: 0.7792\nEpoch 59/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8029 - val_loss: 0.4673 - val_accuracy: 0.7857\nEpoch 60/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8013 - val_loss: 0.4667 - val_accuracy: 0.7922\nEpoch 61/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8046 - val_loss: 0.4689 - val_accuracy: 0.7857\nEpoch 62/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8013 - val_loss: 0.4687 - val_accuracy: 0.7727\nEpoch 63/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8029 - val_loss: 0.4695 - val_accuracy: 0.7857\nEpoch 64/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8078 - val_loss: 0.4697 - val_accuracy: 0.7857\nEpoch 65/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8078 - val_loss: 0.4722 - val_accuracy: 0.7792\nEpoch 66/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8078 - val_loss: 0.4729 - val_accuracy: 0.7922\nEpoch 67/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8013 - val_loss: 0.4706 - val_accuracy: 0.7922\nEpoch 68/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8094 - val_loss: 0.4717 - val_accuracy: 0.7727\nEpoch 69/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8078 - val_loss: 0.4737 - val_accuracy: 0.7792\nEpoch 70/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8062 - val_loss: 0.4722 - val_accuracy: 0.7727\nEpoch 71/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8062 - val_loss: 0.4693 - val_accuracy: 0.7922\nEpoch 72/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8111 - val_loss: 0.4726 - val_accuracy: 0.7857\nEpoch 73/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8111 - val_loss: 0.4743 - val_accuracy: 0.7857\nEpoch 74/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8127 - val_loss: 0.4744 - val_accuracy: 0.7857\nEpoch 75/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3992 - accuracy: 0.8062 - val_loss: 0.4751 - val_accuracy: 0.7792\nEpoch 76/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8111 - val_loss: 0.4722 - val_accuracy: 0.7857\nEpoch 77/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8078 - val_loss: 0.4734 - val_accuracy: 0.7792\nEpoch 78/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8111 - val_loss: 0.4682 - val_accuracy: 0.7922\nEpoch 79/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8160 - val_loss: 0.4703 - val_accuracy: 0.7792\nEpoch 80/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8062 - val_loss: 0.4726 - val_accuracy: 0.7922\nEpoch 81/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8111 - val_loss: 0.4739 - val_accuracy: 0.7857\nEpoch 82/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8046 - val_loss: 0.4741 - val_accuracy: 0.7857\nEpoch 83/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8094 - val_loss: 0.4743 - val_accuracy: 0.7922\nEpoch 84/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8111 - val_loss: 0.4722 - val_accuracy: 0.7922\nEpoch 85/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8176 - val_loss: 0.4776 - val_accuracy: 0.7792\nEpoch 86/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8127 - val_loss: 0.4780 - val_accuracy: 0.7922\nEpoch 87/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8078 - val_loss: 0.4736 - val_accuracy: 0.7922\nEpoch 88/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3914 - accuracy: 0.8111 - val_loss: 0.4733 - val_accuracy: 0.7922\nEpoch 89/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8143 - val_loss: 0.4753 - val_accuracy: 0.7987\nEpoch 90/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8192 - val_loss: 0.4754 - val_accuracy: 0.7792\nEpoch 91/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3894 - accuracy: 0.8078 - val_loss: 0.4742 - val_accuracy: 0.7922\nEpoch 92/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8143 - val_loss: 0.4772 - val_accuracy: 0.7922\nEpoch 93/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8111 - val_loss: 0.4765 - val_accuracy: 0.7662\nEpoch 94/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8208 - val_loss: 0.4751 - val_accuracy: 0.7792\nEpoch 95/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8160 - val_loss: 0.4751 - val_accuracy: 0.7987\nEpoch 96/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8127 - val_loss: 0.4768 - val_accuracy: 0.7857\nEpoch 97/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3871 - accuracy: 0.8176 - val_loss: 0.4809 - val_accuracy: 0.7792\nEpoch 98/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8208 - val_loss: 0.4744 - val_accuracy: 0.8052\nEpoch 99/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8160 - val_loss: 0.4767 - val_accuracy: 0.7987\nEpoch 100/100\n20/20 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8208 - val_loss: 0.4776 - val_accuracy: 0.7922\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fec93f26860>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### **3. To Select Number of Hidden_layers**","metadata":{}},{"cell_type":"code","source":"def build_model(hp):\n    model = Sequential()\n    \n    model.add(Dense(72,activation='relu',input_dim=8))\n    for i in range(hp.Int('num_layers',min_value=1,max_value=8)):\n        model.add(Dense(72,activation='relu'))\n    \n    model.add(Dense(1,activation='sigmoid'))\n    \n    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:12:21.698572Z","iopub.execute_input":"2023-07-03T08:12:21.699051Z","iopub.status.idle":"2023-07-03T08:12:21.707647Z","shell.execute_reply.started":"2023-07-03T08:12:21.699009Z","shell.execute_reply":"2023-07-03T08:12:21.706477Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tuner = kt.RandomSearch(build_model,\n                       objective='val_accuracy',\n                       max_trials=3,\n                       directory='mydir',\n                       project_name='num_layer')","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:12:21.709368Z","iopub.execute_input":"2023-07-03T08:12:21.709703Z","iopub.status.idle":"2023-07-03T08:12:21.780517Z","shell.execute_reply.started":"2023-07-03T08:12:21.709676Z","shell.execute_reply":"2023-07-03T08:12:21.779254Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tuner.search(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:12:21.781819Z","iopub.execute_input":"2023-07-03T08:12:21.782139Z","iopub.status.idle":"2023-07-03T08:12:28.438056Z","shell.execute_reply.started":"2023-07-03T08:12:21.782112Z","shell.execute_reply":"2023-07-03T08:12:28.436901Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Trial 3 Complete [00h 00m 02s]\nval_accuracy: 0.798701286315918\n\nBest val_accuracy So Far: 0.798701286315918\nTotal elapsed time: 00h 00m 07s\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:12:28.439931Z","iopub.execute_input":"2023-07-03T08:12:28.440377Z","iopub.status.idle":"2023-07-03T08:12:28.448431Z","shell.execute_reply.started":"2023-07-03T08:12:28.440337Z","shell.execute_reply":"2023-07-03T08:12:28.447303Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'num_layers': 4}"},"metadata":{}}]},{"cell_type":"code","source":"model = tuner.get_best_models(num_models=1)[0]\n\nmodel.fit(X_train,Y_train,epochs=100,initial_epoch=4,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-03T08:18:01.883115Z","iopub.execute_input":"2023-07-03T08:18:01.883516Z","iopub.status.idle":"2023-07-03T08:18:11.596044Z","shell.execute_reply.started":"2023-07-03T08:18:01.883483Z","shell.execute_reply":"2023-07-03T08:18:11.594975Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 5/100\n20/20 [==============================] - 1s 14ms/step - loss: 0.4529 - accuracy: 0.7769 - val_loss: 0.4632 - val_accuracy: 0.7597\nEpoch 6/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7883 - val_loss: 0.4633 - val_accuracy: 0.7857\nEpoch 7/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.8013 - val_loss: 0.4844 - val_accuracy: 0.7468\nEpoch 8/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.7964 - val_loss: 0.5061 - val_accuracy: 0.7468\nEpoch 9/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.7997 - val_loss: 0.4882 - val_accuracy: 0.7662\nEpoch 10/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.7948 - val_loss: 0.4857 - val_accuracy: 0.7338\nEpoch 11/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8078 - val_loss: 0.4917 - val_accuracy: 0.7338\nEpoch 12/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8192 - val_loss: 0.5069 - val_accuracy: 0.7532\nEpoch 13/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3844 - accuracy: 0.8290 - val_loss: 0.5438 - val_accuracy: 0.7403\nEpoch 14/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3737 - accuracy: 0.8339 - val_loss: 0.5060 - val_accuracy: 0.7597\nEpoch 15/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8339 - val_loss: 0.5408 - val_accuracy: 0.7338\nEpoch 16/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8469 - val_loss: 0.5310 - val_accuracy: 0.7338\nEpoch 17/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8485 - val_loss: 0.5066 - val_accuracy: 0.7403\nEpoch 18/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8567 - val_loss: 0.5509 - val_accuracy: 0.7597\nEpoch 19/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3288 - accuracy: 0.8502 - val_loss: 0.5290 - val_accuracy: 0.7727\nEpoch 20/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.8534 - val_loss: 0.5583 - val_accuracy: 0.7532\nEpoch 21/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3084 - accuracy: 0.8664 - val_loss: 0.6101 - val_accuracy: 0.7208\nEpoch 22/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2945 - accuracy: 0.8811 - val_loss: 0.6492 - val_accuracy: 0.7468\nEpoch 23/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8632 - val_loss: 0.6326 - val_accuracy: 0.7078\nEpoch 24/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2762 - accuracy: 0.8876 - val_loss: 0.6176 - val_accuracy: 0.7208\nEpoch 25/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.8876 - val_loss: 0.6324 - val_accuracy: 0.7468\nEpoch 26/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.8958 - val_loss: 0.6903 - val_accuracy: 0.7273\nEpoch 27/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2453 - accuracy: 0.9023 - val_loss: 0.9704 - val_accuracy: 0.6299\nEpoch 28/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2386 - accuracy: 0.9088 - val_loss: 0.8229 - val_accuracy: 0.6558\nEpoch 29/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2325 - accuracy: 0.9039 - val_loss: 0.8248 - val_accuracy: 0.7013\nEpoch 30/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2025 - accuracy: 0.9186 - val_loss: 0.7894 - val_accuracy: 0.7208\nEpoch 31/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.2129 - accuracy: 0.9121 - val_loss: 0.8333 - val_accuracy: 0.6818\nEpoch 32/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.9251 - val_loss: 0.8097 - val_accuracy: 0.7338\nEpoch 33/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1836 - accuracy: 0.9283 - val_loss: 0.8646 - val_accuracy: 0.6948\nEpoch 34/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1689 - accuracy: 0.9251 - val_loss: 0.9028 - val_accuracy: 0.7208\nEpoch 35/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9267 - val_loss: 0.9967 - val_accuracy: 0.6753\nEpoch 36/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9316 - val_loss: 0.9362 - val_accuracy: 0.7208\nEpoch 37/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1464 - accuracy: 0.9397 - val_loss: 0.9820 - val_accuracy: 0.7208\nEpoch 38/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1593 - accuracy: 0.9479 - val_loss: 0.9901 - val_accuracy: 0.7208\nEpoch 39/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9625 - val_loss: 1.0581 - val_accuracy: 0.7403\nEpoch 40/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1277 - accuracy: 0.9430 - val_loss: 1.0511 - val_accuracy: 0.7273\nEpoch 41/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9609 - val_loss: 1.1668 - val_accuracy: 0.7273\nEpoch 42/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9609 - val_loss: 1.1138 - val_accuracy: 0.7078\nEpoch 43/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9691 - val_loss: 1.3769 - val_accuracy: 0.6688\nEpoch 44/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0994 - accuracy: 0.9625 - val_loss: 1.2495 - val_accuracy: 0.6818\nEpoch 45/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9707 - val_loss: 1.3840 - val_accuracy: 0.7013\nEpoch 46/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9593 - val_loss: 1.2735 - val_accuracy: 0.7078\nEpoch 47/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9805 - val_loss: 1.3939 - val_accuracy: 0.7013\nEpoch 48/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9658 - val_loss: 1.4505 - val_accuracy: 0.6948\nEpoch 49/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9886 - val_loss: 1.5534 - val_accuracy: 0.6948\nEpoch 50/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9707 - val_loss: 1.5288 - val_accuracy: 0.7013\nEpoch 51/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0435 - accuracy: 0.9886 - val_loss: 1.7122 - val_accuracy: 0.7013\nEpoch 52/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0549 - accuracy: 0.9739 - val_loss: 1.5827 - val_accuracy: 0.7208\nEpoch 53/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9723 - val_loss: 1.6085 - val_accuracy: 0.6948\nEpoch 54/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9984 - val_loss: 1.8161 - val_accuracy: 0.6818\nEpoch 55/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0726 - accuracy: 0.9723 - val_loss: 1.7591 - val_accuracy: 0.6753\nEpoch 56/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 1.9617 - val_accuracy: 0.7273\nEpoch 57/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.1049 - accuracy: 0.9658 - val_loss: 1.7054 - val_accuracy: 0.7143\nEpoch 58/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9919 - val_loss: 1.8857 - val_accuracy: 0.6883\nEpoch 59/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9935 - val_loss: 1.9124 - val_accuracy: 0.6948\nEpoch 60/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9772 - val_loss: 1.9171 - val_accuracy: 0.7078\nEpoch 61/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9984 - val_loss: 1.9420 - val_accuracy: 0.7078\nEpoch 62/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9837 - val_loss: 2.1850 - val_accuracy: 0.6688\nEpoch 63/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: 2.1340 - val_accuracy: 0.7013\nEpoch 64/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9739 - val_loss: 2.1027 - val_accuracy: 0.6818\nEpoch 65/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 2.1250 - val_accuracy: 0.6818\nEpoch 66/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0469 - accuracy: 0.9886 - val_loss: 2.2168 - val_accuracy: 0.6688\nEpoch 67/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9821 - val_loss: 2.1181 - val_accuracy: 0.7078\nEpoch 68/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9967 - val_loss: 2.1438 - val_accuracy: 0.7078\nEpoch 69/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0475 - accuracy: 0.9853 - val_loss: 2.1121 - val_accuracy: 0.6883\nEpoch 70/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 2.1383 - val_accuracy: 0.6883\nEpoch 71/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.1689 - val_accuracy: 0.7143\nEpoch 72/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 2.3225 - val_accuracy: 0.7078\nEpoch 73/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9886 - val_loss: 2.2411 - val_accuracy: 0.7403\nEpoch 74/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9886 - val_loss: 2.3317 - val_accuracy: 0.6818\nEpoch 75/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 2.3473 - val_accuracy: 0.6948\nEpoch 76/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9821 - val_loss: 2.4015 - val_accuracy: 0.7078\nEpoch 77/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9935 - val_loss: 2.5104 - val_accuracy: 0.7143\nEpoch 78/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 0.9984 - val_loss: 2.3830 - val_accuracy: 0.7078\nEpoch 79/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 2.4898 - val_accuracy: 0.7273\nEpoch 80/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9821 - val_loss: 2.3746 - val_accuracy: 0.7338\nEpoch 81/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9788 - val_loss: 2.4339 - val_accuracy: 0.7273\nEpoch 82/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9935 - val_loss: 2.6397 - val_accuracy: 0.6753\nEpoch 83/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 2.4055 - val_accuracy: 0.7078\nEpoch 84/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7362 - val_accuracy: 0.7013\nEpoch 85/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9772 - val_loss: 2.4807 - val_accuracy: 0.7078\nEpoch 86/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9951 - val_loss: 2.8574 - val_accuracy: 0.6818\nEpoch 87/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9935 - val_loss: 2.6409 - val_accuracy: 0.7013\nEpoch 88/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9870 - val_loss: 2.6490 - val_accuracy: 0.6883\nEpoch 89/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.6881 - val_accuracy: 0.6883\nEpoch 90/100\n20/20 [==============================] - 0s 4ms/step - loss: 7.1996e-04 - accuracy: 1.0000 - val_loss: 2.7811 - val_accuracy: 0.6948\nEpoch 91/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9821 - val_loss: 2.9802 - val_accuracy: 0.7208\nEpoch 92/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 2.9063 - val_accuracy: 0.7013\nEpoch 93/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9935 - val_loss: 2.9464 - val_accuracy: 0.6948\nEpoch 94/100\n20/20 [==============================] - 0s 5ms/step - loss: 9.0161e-04 - accuracy: 1.0000 - val_loss: 2.8650 - val_accuracy: 0.7013\nEpoch 95/100\n20/20 [==============================] - 0s 5ms/step - loss: 4.9311e-04 - accuracy: 1.0000 - val_loss: 2.9694 - val_accuracy: 0.7078\nEpoch 96/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9902 - val_loss: 2.7734 - val_accuracy: 0.7013\nEpoch 97/100\n20/20 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9935 - val_loss: 3.4559 - val_accuracy: 0.6364\nEpoch 98/100\n20/20 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9902 - val_loss: 2.8857 - val_accuracy: 0.7078\nEpoch 99/100\n20/20 [==============================] - 0s 4ms/step - loss: 7.8413e-04 - accuracy: 1.0000 - val_loss: 2.8866 - val_accuracy: 0.6948\nEpoch 100/100\n20/20 [==============================] - 0s 4ms/step - loss: 4.0103e-04 - accuracy: 1.0000 - val_loss: 2.9462 - val_accuracy: 0.6948\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fec92d07f10>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### **4. All Changes in one model: (layer ,node ,Activation ,dropout ,optimizer)**","metadata":{}},{"cell_type":"code","source":"def build_model2(hp):\n    \n    model = Sequential()\n    \n    counter = 0\n    \n    for i in range(hp.Int('num_layers',min_value=1,max_value=10)):\n        \n        if counter == 0:  # First layer\n            \n            model.add(Dense(hp.Int('units' + str(i),min_value=8,max_value=128),# No.of nodes\n                           activation= hp.Choice('activation' + str(i),values=['relu','tanh','sigmoid']),# Best activation\n                           input_dim= 8))\n            model.add(Dropout(hp.Choice('dropout' + str(i),values=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))# no.of dropout nodes\n            \n        else: # Hidden layer\n            \n            model.add(Dense(hp.Int('units' + str(i),min_value=8,max_value=128),# No. of nodes\n                           activation= hp.Choice('activation' + str(i),values=['relu','tanh','sigmoid'])))# Best activation\n            model.add(Dropout(hp.Choice('dropout' + str(i),values=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])))\n            \n        counter += 1\n    model.add(Dense(1,activation='sigmoid'))  # Outer layer\n    \n    model.compile(optimizer=hp.Choice('optimizer',values=['rmsprop','adam','sgd','nadam','adadelta']),\n                 loss= 'binary_crossentropy',\n                 metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-07-03T09:25:02.842718Z","iopub.execute_input":"2023-07-03T09:25:02.843265Z","iopub.status.idle":"2023-07-03T09:25:02.856274Z","shell.execute_reply.started":"2023-07-03T09:25:02.843226Z","shell.execute_reply":"2023-07-03T09:25:02.855345Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"tuner = kt.RandomSearch(build_model2,\n                       objective='val_accuracy',\n                       max_trials=3,\n                       directory='mydir',\n                       project_name='final')","metadata":{"execution":{"iopub.status.busy":"2023-07-03T09:25:09.022009Z","iopub.execute_input":"2023-07-03T09:25:09.022439Z","iopub.status.idle":"2023-07-03T09:25:09.072576Z","shell.execute_reply.started":"2023-07-03T09:25:09.022374Z","shell.execute_reply":"2023-07-03T09:25:09.071258Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"tuner.search(X_train,Y_train,epochs=5,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-03T09:25:11.443544Z","iopub.execute_input":"2023-07-03T09:25:11.443973Z","iopub.status.idle":"2023-07-03T09:25:26.188616Z","shell.execute_reply.started":"2023-07-03T09:25:11.443938Z","shell.execute_reply":"2023-07-03T09:25:26.187151Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Trial 3 Complete [00h 00m 03s]\nval_accuracy: 0.7077922224998474\n\nBest val_accuracy So Far: 0.7077922224998474\nTotal elapsed time: 00h 00m 15s\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2023-07-03T09:26:11.101642Z","iopub.execute_input":"2023-07-03T09:26:11.102134Z","iopub.status.idle":"2023-07-03T09:26:11.111657Z","shell.execute_reply.started":"2023-07-03T09:26:11.102096Z","shell.execute_reply":"2023-07-03T09:26:11.110423Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"{'num_layers': 9,\n 'units0': 10,\n 'activation0': 'relu',\n 'dropout0': 0.5,\n 'optimizer': 'nadam',\n 'units1': 8,\n 'activation1': 'relu',\n 'dropout1': 0.1,\n 'units2': 8,\n 'activation2': 'relu',\n 'dropout2': 0.1,\n 'units3': 8,\n 'activation3': 'relu',\n 'dropout3': 0.1,\n 'units4': 8,\n 'activation4': 'relu',\n 'dropout4': 0.1,\n 'units5': 8,\n 'activation5': 'relu',\n 'dropout5': 0.1,\n 'units6': 8,\n 'activation6': 'relu',\n 'dropout6': 0.1,\n 'units7': 8,\n 'activation7': 'relu',\n 'dropout7': 0.1,\n 'units8': 8,\n 'activation8': 'relu',\n 'dropout8': 0.1}"},"metadata":{}}]},{"cell_type":"code","source":"model = tuner.get_best_models(num_models=1)[0]\n\nmodel.fit(X_train,Y_train,epochs=200,initial_epoch=4,validation_data=(X_test,Y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-03T09:39:18.397682Z","iopub.execute_input":"2023-07-03T09:39:18.398152Z","iopub.status.idle":"2023-07-03T09:39:46.572441Z","shell.execute_reply.started":"2023-07-03T09:39:18.398119Z","shell.execute_reply":"2023-07-03T09:39:46.571273Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Epoch 5/200\n20/20 [==============================] - 5s 18ms/step - loss: 0.6863 - accuracy: 0.6368 - val_loss: 0.6768 - val_accuracy: 0.7078\nEpoch 6/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6806 - accuracy: 0.6352 - val_loss: 0.6645 - val_accuracy: 0.7078\nEpoch 7/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6729 - accuracy: 0.6368 - val_loss: 0.6535 - val_accuracy: 0.7078\nEpoch 8/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.6656 - accuracy: 0.6368 - val_loss: 0.6429 - val_accuracy: 0.7078\nEpoch 9/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6650 - accuracy: 0.6368 - val_loss: 0.6342 - val_accuracy: 0.7078\nEpoch 10/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.6621 - accuracy: 0.6368 - val_loss: 0.6297 - val_accuracy: 0.7078\nEpoch 11/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.6384 - val_loss: 0.6213 - val_accuracy: 0.7078\nEpoch 12/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6499 - accuracy: 0.6384 - val_loss: 0.6115 - val_accuracy: 0.7078\nEpoch 13/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6429 - accuracy: 0.6401 - val_loss: 0.6007 - val_accuracy: 0.7078\nEpoch 14/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6349 - accuracy: 0.6384 - val_loss: 0.5857 - val_accuracy: 0.7078\nEpoch 15/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6283 - accuracy: 0.6482 - val_loss: 0.5732 - val_accuracy: 0.7078\nEpoch 16/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6133 - accuracy: 0.6612 - val_loss: 0.5615 - val_accuracy: 0.7532\nEpoch 17/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.6889 - val_loss: 0.5523 - val_accuracy: 0.7727\nEpoch 18/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.6857 - val_loss: 0.5472 - val_accuracy: 0.7597\nEpoch 19/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.6775 - val_loss: 0.5420 - val_accuracy: 0.7532\nEpoch 20/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6041 - accuracy: 0.6922 - val_loss: 0.5373 - val_accuracy: 0.7468\nEpoch 21/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.6808 - val_loss: 0.5359 - val_accuracy: 0.7403\nEpoch 22/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5878 - accuracy: 0.6954 - val_loss: 0.5255 - val_accuracy: 0.7338\nEpoch 23/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.6971 - val_loss: 0.5272 - val_accuracy: 0.7403\nEpoch 24/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5894 - accuracy: 0.6954 - val_loss: 0.5219 - val_accuracy: 0.7403\nEpoch 25/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.7248 - val_loss: 0.5191 - val_accuracy: 0.7468\nEpoch 26/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.6987 - val_loss: 0.5146 - val_accuracy: 0.7532\nEpoch 27/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5552 - accuracy: 0.7182 - val_loss: 0.5078 - val_accuracy: 0.7468\nEpoch 28/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7296 - val_loss: 0.5132 - val_accuracy: 0.7273\nEpoch 29/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5814 - accuracy: 0.6987 - val_loss: 0.5106 - val_accuracy: 0.7532\nEpoch 30/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.7036 - val_loss: 0.5138 - val_accuracy: 0.7338\nEpoch 31/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5715 - accuracy: 0.7394 - val_loss: 0.5128 - val_accuracy: 0.7338\nEpoch 32/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5919 - accuracy: 0.7215 - val_loss: 0.5102 - val_accuracy: 0.7468\nEpoch 33/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5801 - accuracy: 0.6906 - val_loss: 0.5186 - val_accuracy: 0.7468\nEpoch 34/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5825 - accuracy: 0.7020 - val_loss: 0.5147 - val_accuracy: 0.7532\nEpoch 35/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5680 - accuracy: 0.7150 - val_loss: 0.5116 - val_accuracy: 0.7468\nEpoch 36/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5643 - accuracy: 0.7215 - val_loss: 0.5084 - val_accuracy: 0.7532\nEpoch 37/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5826 - accuracy: 0.7182 - val_loss: 0.5074 - val_accuracy: 0.7532\nEpoch 38/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5574 - accuracy: 0.7052 - val_loss: 0.5068 - val_accuracy: 0.7597\nEpoch 39/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.5748 - accuracy: 0.7134 - val_loss: 0.5091 - val_accuracy: 0.7338\nEpoch 40/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.5625 - accuracy: 0.7101 - val_loss: 0.5128 - val_accuracy: 0.7338\nEpoch 41/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.5741 - accuracy: 0.7215 - val_loss: 0.5145 - val_accuracy: 0.7403\nEpoch 42/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.5689 - accuracy: 0.7101 - val_loss: 0.5134 - val_accuracy: 0.7597\nEpoch 43/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.5775 - accuracy: 0.6922 - val_loss: 0.5090 - val_accuracy: 0.7532\nEpoch 44/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5708 - accuracy: 0.7166 - val_loss: 0.5142 - val_accuracy: 0.7597\nEpoch 45/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5547 - accuracy: 0.7182 - val_loss: 0.5146 - val_accuracy: 0.7597\nEpoch 46/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5436 - accuracy: 0.7280 - val_loss: 0.5102 - val_accuracy: 0.7468\nEpoch 47/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.5621 - accuracy: 0.7003 - val_loss: 0.5097 - val_accuracy: 0.7532\nEpoch 48/200\n20/20 [==============================] - 0s 8ms/step - loss: 0.5550 - accuracy: 0.6954 - val_loss: 0.5050 - val_accuracy: 0.7597\nEpoch 49/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5734 - accuracy: 0.7068 - val_loss: 0.5041 - val_accuracy: 0.7662\nEpoch 50/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.5579 - accuracy: 0.7199 - val_loss: 0.5059 - val_accuracy: 0.7532\nEpoch 51/200\n20/20 [==============================] - 0s 8ms/step - loss: 0.5375 - accuracy: 0.7264 - val_loss: 0.5052 - val_accuracy: 0.7468\nEpoch 52/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5618 - accuracy: 0.7280 - val_loss: 0.5063 - val_accuracy: 0.7403\nEpoch 53/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.5485 - accuracy: 0.7313 - val_loss: 0.5092 - val_accuracy: 0.7468\nEpoch 54/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.5404 - accuracy: 0.7231 - val_loss: 0.5037 - val_accuracy: 0.7468\nEpoch 55/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.5615 - accuracy: 0.7085 - val_loss: 0.5002 - val_accuracy: 0.7403\nEpoch 56/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.7068 - val_loss: 0.5083 - val_accuracy: 0.7468\nEpoch 57/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5435 - accuracy: 0.7264 - val_loss: 0.5100 - val_accuracy: 0.7403\nEpoch 58/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.7573 - val_loss: 0.5047 - val_accuracy: 0.7468\nEpoch 59/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5458 - accuracy: 0.7248 - val_loss: 0.5012 - val_accuracy: 0.7532\nEpoch 60/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.7443 - val_loss: 0.4956 - val_accuracy: 0.7532\nEpoch 61/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5489 - accuracy: 0.7329 - val_loss: 0.4959 - val_accuracy: 0.7532\nEpoch 62/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5429 - accuracy: 0.7280 - val_loss: 0.4955 - val_accuracy: 0.7597\nEpoch 63/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5615 - accuracy: 0.7134 - val_loss: 0.4981 - val_accuracy: 0.7597\nEpoch 64/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.7394 - val_loss: 0.4984 - val_accuracy: 0.7403\nEpoch 65/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7622 - val_loss: 0.4961 - val_accuracy: 0.7403\nEpoch 66/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5499 - accuracy: 0.7166 - val_loss: 0.4926 - val_accuracy: 0.7403\nEpoch 67/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5621 - accuracy: 0.7264 - val_loss: 0.4917 - val_accuracy: 0.7468\nEpoch 68/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7329 - val_loss: 0.4934 - val_accuracy: 0.7403\nEpoch 69/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5373 - accuracy: 0.7329 - val_loss: 0.4924 - val_accuracy: 0.7468\nEpoch 70/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7590 - val_loss: 0.4863 - val_accuracy: 0.7662\nEpoch 71/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5502 - accuracy: 0.7199 - val_loss: 0.4907 - val_accuracy: 0.7532\nEpoch 72/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.7622 - val_loss: 0.4959 - val_accuracy: 0.7532\nEpoch 73/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5316 - accuracy: 0.7329 - val_loss: 0.4950 - val_accuracy: 0.7468\nEpoch 74/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.7345 - val_loss: 0.4962 - val_accuracy: 0.7468\nEpoch 75/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5504 - accuracy: 0.7166 - val_loss: 0.4944 - val_accuracy: 0.7468\nEpoch 76/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5424 - accuracy: 0.7052 - val_loss: 0.4926 - val_accuracy: 0.7468\nEpoch 77/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5511 - accuracy: 0.7296 - val_loss: 0.4933 - val_accuracy: 0.7468\nEpoch 78/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5458 - accuracy: 0.7345 - val_loss: 0.4913 - val_accuracy: 0.7532\nEpoch 79/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5411 - accuracy: 0.7378 - val_loss: 0.4922 - val_accuracy: 0.7532\nEpoch 80/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7492 - val_loss: 0.4921 - val_accuracy: 0.7468\nEpoch 81/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5197 - accuracy: 0.7378 - val_loss: 0.4880 - val_accuracy: 0.7468\nEpoch 82/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5430 - accuracy: 0.7199 - val_loss: 0.4858 - val_accuracy: 0.7597\nEpoch 83/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.7264 - val_loss: 0.4919 - val_accuracy: 0.7532\nEpoch 84/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5125 - accuracy: 0.7492 - val_loss: 0.4972 - val_accuracy: 0.7468\nEpoch 85/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5533 - accuracy: 0.7166 - val_loss: 0.4942 - val_accuracy: 0.7532\nEpoch 86/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7329 - val_loss: 0.4962 - val_accuracy: 0.7532\nEpoch 87/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5458 - accuracy: 0.7296 - val_loss: 0.4972 - val_accuracy: 0.7468\nEpoch 88/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5392 - accuracy: 0.7231 - val_loss: 0.4914 - val_accuracy: 0.7468\nEpoch 89/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7117 - val_loss: 0.4897 - val_accuracy: 0.7597\nEpoch 90/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7394 - val_loss: 0.4899 - val_accuracy: 0.7468\nEpoch 91/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.7524 - val_loss: 0.4903 - val_accuracy: 0.7532\nEpoch 92/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5400 - accuracy: 0.7313 - val_loss: 0.4887 - val_accuracy: 0.7597\nEpoch 93/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.7541 - val_loss: 0.4922 - val_accuracy: 0.7532\nEpoch 94/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5329 - accuracy: 0.7362 - val_loss: 0.4868 - val_accuracy: 0.7662\nEpoch 95/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.7459 - val_loss: 0.4863 - val_accuracy: 0.7597\nEpoch 96/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5200 - accuracy: 0.7329 - val_loss: 0.4867 - val_accuracy: 0.7532\nEpoch 97/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5438 - accuracy: 0.7541 - val_loss: 0.4915 - val_accuracy: 0.7468\nEpoch 98/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.7248 - val_loss: 0.4910 - val_accuracy: 0.7468\nEpoch 99/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.7541 - val_loss: 0.4899 - val_accuracy: 0.7597\nEpoch 100/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5108 - accuracy: 0.7476 - val_loss: 0.4879 - val_accuracy: 0.7532\nEpoch 101/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7459 - val_loss: 0.4898 - val_accuracy: 0.7468\nEpoch 102/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5430 - accuracy: 0.7329 - val_loss: 0.4886 - val_accuracy: 0.7532\nEpoch 103/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7476 - val_loss: 0.4864 - val_accuracy: 0.7468\nEpoch 104/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.7573 - val_loss: 0.4865 - val_accuracy: 0.7532\nEpoch 105/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.7459 - val_loss: 0.4901 - val_accuracy: 0.7468\nEpoch 106/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5130 - accuracy: 0.7199 - val_loss: 0.4880 - val_accuracy: 0.7532\nEpoch 107/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.7492 - val_loss: 0.4856 - val_accuracy: 0.7468\nEpoch 108/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7524 - val_loss: 0.4812 - val_accuracy: 0.7468\nEpoch 109/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5259 - accuracy: 0.7280 - val_loss: 0.4823 - val_accuracy: 0.7468\nEpoch 110/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5077 - accuracy: 0.7378 - val_loss: 0.4828 - val_accuracy: 0.7532\nEpoch 111/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5265 - accuracy: 0.7313 - val_loss: 0.4838 - val_accuracy: 0.7468\nEpoch 112/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5508 - accuracy: 0.7052 - val_loss: 0.4925 - val_accuracy: 0.7597\nEpoch 113/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5323 - accuracy: 0.7427 - val_loss: 0.4918 - val_accuracy: 0.7468\nEpoch 114/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5175 - accuracy: 0.7492 - val_loss: 0.4922 - val_accuracy: 0.7403\nEpoch 115/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7182 - val_loss: 0.4940 - val_accuracy: 0.7532\nEpoch 116/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5105 - accuracy: 0.7378 - val_loss: 0.4940 - val_accuracy: 0.7532\nEpoch 117/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5035 - accuracy: 0.7345 - val_loss: 0.4881 - val_accuracy: 0.7532\nEpoch 118/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7606 - val_loss: 0.4832 - val_accuracy: 0.7403\nEpoch 119/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5043 - accuracy: 0.7362 - val_loss: 0.4802 - val_accuracy: 0.7338\nEpoch 120/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5375 - accuracy: 0.7264 - val_loss: 0.4814 - val_accuracy: 0.7468\nEpoch 121/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5107 - accuracy: 0.7427 - val_loss: 0.4826 - val_accuracy: 0.7468\nEpoch 122/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7557 - val_loss: 0.4855 - val_accuracy: 0.7468\nEpoch 123/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5401 - accuracy: 0.7443 - val_loss: 0.4902 - val_accuracy: 0.7403\nEpoch 124/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5430 - accuracy: 0.7394 - val_loss: 0.4945 - val_accuracy: 0.7403\nEpoch 125/200\n20/20 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.7541 - val_loss: 0.4905 - val_accuracy: 0.7468\nEpoch 126/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.7313 - val_loss: 0.4872 - val_accuracy: 0.7468\nEpoch 127/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5210 - accuracy: 0.7280 - val_loss: 0.4877 - val_accuracy: 0.7468\nEpoch 128/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5169 - accuracy: 0.7394 - val_loss: 0.4877 - val_accuracy: 0.7468\nEpoch 129/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.7410 - val_loss: 0.4833 - val_accuracy: 0.7403\nEpoch 130/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5034 - accuracy: 0.7443 - val_loss: 0.4877 - val_accuracy: 0.7532\nEpoch 131/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7801 - val_loss: 0.4855 - val_accuracy: 0.7532\nEpoch 132/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.7508 - val_loss: 0.4831 - val_accuracy: 0.7403\nEpoch 133/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7459 - val_loss: 0.4869 - val_accuracy: 0.7403\nEpoch 134/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5087 - accuracy: 0.7378 - val_loss: 0.4894 - val_accuracy: 0.7532\nEpoch 135/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.7492 - val_loss: 0.4876 - val_accuracy: 0.7532\nEpoch 136/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5316 - accuracy: 0.7264 - val_loss: 0.4849 - val_accuracy: 0.7403\nEpoch 137/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7541 - val_loss: 0.4850 - val_accuracy: 0.7597\nEpoch 138/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7345 - val_loss: 0.4857 - val_accuracy: 0.7532\nEpoch 139/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7622 - val_loss: 0.4846 - val_accuracy: 0.7532\nEpoch 140/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5051 - accuracy: 0.7476 - val_loss: 0.4845 - val_accuracy: 0.7532\nEpoch 141/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7590 - val_loss: 0.4860 - val_accuracy: 0.7532\nEpoch 142/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7394 - val_loss: 0.4886 - val_accuracy: 0.7532\nEpoch 143/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7671 - val_loss: 0.4869 - val_accuracy: 0.7532\nEpoch 144/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7573 - val_loss: 0.4835 - val_accuracy: 0.7597\nEpoch 145/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4935 - accuracy: 0.7508 - val_loss: 0.4846 - val_accuracy: 0.7662\nEpoch 146/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5211 - accuracy: 0.7459 - val_loss: 0.4874 - val_accuracy: 0.7532\nEpoch 147/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7443 - val_loss: 0.4859 - val_accuracy: 0.7532\nEpoch 148/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7378 - val_loss: 0.4830 - val_accuracy: 0.7468\nEpoch 149/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.7134 - val_loss: 0.4815 - val_accuracy: 0.7532\nEpoch 150/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7443 - val_loss: 0.4833 - val_accuracy: 0.7662\nEpoch 151/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5053 - accuracy: 0.7410 - val_loss: 0.4853 - val_accuracy: 0.7662\nEpoch 152/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.7296 - val_loss: 0.4873 - val_accuracy: 0.7662\nEpoch 153/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7557 - val_loss: 0.4926 - val_accuracy: 0.7468\nEpoch 154/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.7736 - val_loss: 0.4889 - val_accuracy: 0.7532\nEpoch 155/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4870 - accuracy: 0.7508 - val_loss: 0.4873 - val_accuracy: 0.7468\nEpoch 156/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5093 - accuracy: 0.7524 - val_loss: 0.4848 - val_accuracy: 0.7468\nEpoch 157/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7622 - val_loss: 0.4839 - val_accuracy: 0.7662\nEpoch 158/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.7410 - val_loss: 0.4892 - val_accuracy: 0.7662\nEpoch 159/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4973 - accuracy: 0.7508 - val_loss: 0.4886 - val_accuracy: 0.7662\nEpoch 160/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7410 - val_loss: 0.4865 - val_accuracy: 0.7662\nEpoch 161/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5023 - accuracy: 0.7606 - val_loss: 0.4845 - val_accuracy: 0.7597\nEpoch 162/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7476 - val_loss: 0.4838 - val_accuracy: 0.7597\nEpoch 163/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5067 - accuracy: 0.7296 - val_loss: 0.4835 - val_accuracy: 0.7597\nEpoch 164/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.7573 - val_loss: 0.4806 - val_accuracy: 0.7597\nEpoch 165/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5097 - accuracy: 0.7508 - val_loss: 0.4796 - val_accuracy: 0.7792\nEpoch 166/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7606 - val_loss: 0.4846 - val_accuracy: 0.7532\nEpoch 167/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5198 - accuracy: 0.7427 - val_loss: 0.4891 - val_accuracy: 0.7532\nEpoch 168/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.7476 - val_loss: 0.4898 - val_accuracy: 0.7532\nEpoch 169/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.4948 - accuracy: 0.7573 - val_loss: 0.4863 - val_accuracy: 0.7532\nEpoch 170/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4990 - accuracy: 0.7573 - val_loss: 0.4836 - val_accuracy: 0.7532\nEpoch 171/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7443 - val_loss: 0.4828 - val_accuracy: 0.7532\nEpoch 172/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5081 - accuracy: 0.7378 - val_loss: 0.4799 - val_accuracy: 0.7532\nEpoch 173/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.7557 - val_loss: 0.4776 - val_accuracy: 0.7532\nEpoch 174/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.7378 - val_loss: 0.4825 - val_accuracy: 0.7468\nEpoch 175/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7704 - val_loss: 0.4840 - val_accuracy: 0.7468\nEpoch 176/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7573 - val_loss: 0.4825 - val_accuracy: 0.7532\nEpoch 177/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7215 - val_loss: 0.4857 - val_accuracy: 0.7468\nEpoch 178/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5222 - accuracy: 0.7508 - val_loss: 0.4853 - val_accuracy: 0.7597\nEpoch 179/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.7427 - val_loss: 0.4835 - val_accuracy: 0.7597\nEpoch 180/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7573 - val_loss: 0.4824 - val_accuracy: 0.7468\nEpoch 181/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7736 - val_loss: 0.4817 - val_accuracy: 0.7597\nEpoch 182/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7345 - val_loss: 0.4879 - val_accuracy: 0.7532\nEpoch 183/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4781 - accuracy: 0.7492 - val_loss: 0.4892 - val_accuracy: 0.7597\nEpoch 184/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5105 - accuracy: 0.7671 - val_loss: 0.4825 - val_accuracy: 0.7468\nEpoch 185/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5078 - accuracy: 0.7492 - val_loss: 0.4803 - val_accuracy: 0.7468\nEpoch 186/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7459 - val_loss: 0.4835 - val_accuracy: 0.7468\nEpoch 187/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7296 - val_loss: 0.4789 - val_accuracy: 0.7662\nEpoch 188/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7296 - val_loss: 0.4801 - val_accuracy: 0.7597\nEpoch 189/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5176 - accuracy: 0.7541 - val_loss: 0.4848 - val_accuracy: 0.7532\nEpoch 190/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5037 - accuracy: 0.7459 - val_loss: 0.4877 - val_accuracy: 0.7532\nEpoch 191/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5231 - accuracy: 0.7280 - val_loss: 0.4882 - val_accuracy: 0.7662\nEpoch 192/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7622 - val_loss: 0.4861 - val_accuracy: 0.7662\nEpoch 193/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7410 - val_loss: 0.4834 - val_accuracy: 0.7532\nEpoch 194/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.5236 - accuracy: 0.7492 - val_loss: 0.4819 - val_accuracy: 0.7597\nEpoch 195/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.7508 - val_loss: 0.4838 - val_accuracy: 0.7727\nEpoch 196/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.7280 - val_loss: 0.4826 - val_accuracy: 0.7597\nEpoch 197/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5084 - accuracy: 0.7443 - val_loss: 0.4810 - val_accuracy: 0.7532\nEpoch 198/200\n20/20 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7329 - val_loss: 0.4815 - val_accuracy: 0.7468\nEpoch 199/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7476 - val_loss: 0.4797 - val_accuracy: 0.7532\nEpoch 200/200\n20/20 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.7003 - val_loss: 0.4794 - val_accuracy: 0.7662\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fec2c4952a0>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}